hidden = 300, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.931 0.767
hidden = 400, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.936 0.79
hidden = 500, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.926 0.767
hidden = 600, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.91 0.70
hidden = 300, keep_prob = 0.95, num_layers = 2, lr = 0.05, max_grad_norm = 10.0
0.88 0.68

hidden = 400, keep_prob = 0.9, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.92 0.76
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.939 0.812
hidden = 400, keep_prob = 0.7, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.93 0.80
hidden = 400, keep_prob = 0.5, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.92 0.74

hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, no pos ner
0.935 0.79



5.23:
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0
0.737
hidden = 400, keep_prob = 0.8, num_layers = 2, lr = 0.05, max_grad_norm = 10.0
0.756


hidden = 200, keep_prob = 0.8, dense_size = 11, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128
0.797753
hidden = 200, keep_prob = 0.8, dense_size = 100, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128
0.7977
hidden = 200, keep_prob = 0.8, dense_size = 200, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128
0.797753
hidden = 200, keep_prob = 0.8, no dense, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128
<0.3

hidden = 200, keep_prob = 0.8, dense_size = 11, num_layers = 2, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128
0.801498
hidden = 200, keep_prob = 0.8, dense_size = 100, num_layers = 2, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.801498
hidden = 200, keep_prob = 0.8, dense_size = 200, num_layers = 2, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.794007

assert dense_size = len(tagMap) !!!

hidden = 300, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.797753
hidden = 300, keep_prob = 0.8, num_layers = 2, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.801498

hidden = 200, keep_prob = 0.7, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.794007
hidden = 200, keep_prob = 0.6, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.779026

hidden = 200, keep_prob = 0.8, num_layers = 3, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.797753

cross validation:
hidden = 200, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 64):
0.785714, 0.790476, 0.776190, 0.809524, 0.776190
hidden = 200, keep_prob = 0.8, num_layers = 2, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 64):
0.733333, 0.823810, 0.804762, 0.771429, 0.771429

relu activation:
hidden = 200, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.760300

sigmoid:
hidden = 200, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.524345

tanh:
hidden = 200, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):
0.790262
hidden = 200, keep_prob = 0.8, num_layers = 2, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 128):


add dense (size = hidden, act = relu):
0.771536
add dense (size = hidden, act = tanh):
0.760300


hidden = 300, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 64):
0.767790
hidden = 300, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 512):
0.786517

restore dynamic_rnn:
hidden = 300, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 64):
0.737828
0.730337
hidden = 300, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 64):
0.764045
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 64):
0.681648
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 512):
0.752809
hidden = 300, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 512):
0.734082
hidden = 300, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.756554
hidden = 400, keep_prob = 0.95, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.730337
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.756554

use stack_rnn
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.779026

cross validation:
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.747619, 0.752381, 0.776190, 0.700000, 0.800000, 0.755238

change pos/ner to one-hot:
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.812734
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.05, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.782772
hidden = 200, keep_prob = 0.8, num_layers = 1, lr = 0.01, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
0.797753
hidden = 400, keep_prob = 0.8, num_layers = 1, lr = 0.01, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):


hidden = 600, keep_prob = 0.8, num_layers = 1, lr = 0.025, max_grad_norm = 10.0, max_epoch = 100, batch_size = 2048):
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:42<00:00,  2.33it/s]
max acc: 0.761905
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:53<00:00,  1.88it/s]
max acc: 0.771429
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:59<00:00,  1.67it/s]
max acc: 0.795238
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42it/s]
max acc: 0.804762
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:31<00:00,  1.09it/s]
max acc: 0.742857
Average accuracy: 0.775238